# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

AIChat is an all-in-one LLM CLI tool written in Rust, featuring Shell Assistant, CMD & REPL modes, RAG, AI Tools & Agents, and more. This is a fork with additional features for the LASP (Large-Scale AI Systems Programming) final project.

**Repository:** https://github.com/sigoden/aichat (upstream)
**Version:** 0.30.0
**Language:** Rust (Edition 2021)

## Build and Development Commands

### Building
```bash
# Build the project
cargo build

# Build for release (optimized)
cargo build --release

# Run the application
cargo run

# Run with specific arguments
cargo run -- -m gpt-4o "test prompt"
```

### Testing
```bash
# Run all tests
cargo test

# Run tests with output
cargo test -- --nocapture

# Run specific test
cargo test test_name
```

### Code Quality
```bash
# Check code without building
cargo check

# Run clippy for linting
cargo clippy

# Format code
cargo fmt
```

## Architecture

### Core Components

1. **Config System** (`src/config/`)
   - `mod.rs`: Main configuration logic, handles global config, model selection, and role extraction
   - `environments.rs`: **NEW** Environment detection (OS, shell, package manager, system info)
   - `role.rs`: Role definitions and management
   - `session.rs`: Session persistence and management
   - `agent.rs`: AI agent configurations
   - `input.rs`: Input handling and processing

2. **REPL System** (`src/repl/`)
   - `mod.rs`: Main REPL loop, command handling, and **new `.export` command**
   - `completer.rs`: Tab completion
   - `highlighter.rs`: Syntax highlighting
   - `prompt.rs`: Custom REPL prompts

3. **Client System** (`src/client/`)
   - Supports 20+ LLM providers (OpenAI, Claude, Gemini, Ollama, etc.)
   - Each provider has its own module (e.g., `openai.rs`, `claude.rs`, `gemini.rs`)
   - `common.rs`: Shared client utilities
   - `message.rs`: Message formatting and handling

4. **RAG System** (`src/rag/`)
   - Document loading, chunking, embedding, and retrieval
   - Supports multiple document types via external loaders

5. **Function System** (`src/function.rs`)
   - Function calling and tool integration
   - MCP (Model Context Protocol) support

6. **Rendering** (`src/render/`)
   - Markdown rendering with syntax highlighting
   - Stream processing for real-time output

## New Features Added (LASP Final Project)

### 1. Environment Awareness (Auto-Setup)
**Status:** ✅ Fully Implemented

**Implementation:**
- `src/config/environments.rs`: Complete environment detection system
- Detects: OS type, Shell type, Package Manager, CPU cores, Memory, Disk space, GPU
- Automatically injects environment context into AI prompts via `EnvProfile::to_prompt_context()`
- Integration in `src/config/mod.rs`: `Config::extract_role()` method adds environment info to all role prompts

**How it works:**
- When a role is extracted, `EnvProfile::detect()` runs to gather system information
- The environment context is prepended to the role's prompt
- AI models receive XML-formatted environment data: `<user_environment>...</user_environment>`
- This ensures commands generated by AI match the user's actual environment (e.g., `brew` for macOS, `apt` for Ubuntu)

**Files modified:**
- `src/config/environments.rs` (new file)
- `src/config/mod.rs` (environment injection)
- `src/config/role.rs` (added `set_prompt()` method)
- `Cargo.toml` (added dependencies: `sysinfo`, `which`, `ping`)

### 2. Session Export to Markdown
**Status:** ✅ Fully Implemented

**Implementation:**
- New REPL command: `.export [filename]`
- Located in `src/repl/mod.rs`: `export_session_markdown()` function (line ~955)
- Exports current session as a formatted Markdown file
- Default filename: `session-{name}.md`

**Usage:**
```bash
# In REPL mode
.export                    # Export to session-{name}.md
.export my-session.md      # Export to custom filename
```

**Features:**
- Preserves conversation structure
- Includes role/agent information
- Markdown-formatted code blocks
- Timestamps and metadata

### 3. Safe and Reversible Execution
**Status:** ⏳ Partially Implemented

**Implemented:**
- Environment awareness (helps generate safer, OS-appropriate commands)

**Not Yet Implemented:**
- Sandbox preview with diff view
- Automatic file backups
- Rollback scripts
- Command Tutor mode with explanations

## Important Code Patterns

### Environment Detection Flow
```rust
// 1. Detect environment
let env = EnvProfile::detect();

// 2. Generate context for AI
let env_ctx = env.to_prompt_context();

// 3. Inject into prompt
let new_prompt = format!("{}\n\n{}", env_ctx, original_prompt);
role.set_prompt(new_prompt);
```

### Adding New REPL Commands
1. Add command definition to `REPL_COMMANDS` array in `src/repl/mod.rs`
2. Add command handler in the match statement in `handle_command()`
3. Example pattern:
```rust
ReplCommand::new(".mycommand", "Description", AssertState::pass()),

// In handle_command():
".mycommand" => {
    my_command_handler(config, args)?;
}
```

### Working with Sessions
- Sessions are stored in `~/.config/aichat/sessions/`
- Session state includes messages, role, and metadata
- Sessions can be compressed when they exceed `compress_threshold`

### Working with Roles
- Roles define system prompts and model configurations
- Stored in `~/.config/aichat/roles/`
- Can be created dynamically or loaded from YAML files

## Configuration

**Config file location:** `~/.config/aichat/config.yaml`

**Key directories:**
- `~/.config/aichat/roles/` - Role definitions
- `~/.config/aichat/sessions/` - Saved sessions
- `~/.config/aichat/agents/` - Agent configurations
- `~/.config/aichat/rags/` - RAG document stores
- `~/.config/aichat/functions/` - Function definitions

## Testing the New Features

### Test Environment Detection
```bash
# Run aichat and check .info output
cargo run
> .info

# Check if environment context is in prompts
# Use dry-run mode to see the full prompt
cargo run -- --dry-run -c "list files"
```

### Test Session Export
```bash
# Start a session and have a conversation
cargo run
> .session test-session
> Hello, this is a test
> .export test-output.md
# Check that test-output.md was created with proper formatting
```

## Common Development Patterns

### Adding System Information to Environment Detection
1. Add new field to `EnvProfile` struct in `src/config/environments.rs`
2. Implement detection logic in a new function (e.g., `detect_cpu_info()`)
3. Call detection function in `EnvProfile::detect()`
4. Update `to_prompt_context()` to include the new information

### Modifying Prompt Injection
- Environment context injection happens in `Config::extract_role()` in `src/config/mod.rs`
- The format is XML-tagged for clear parsing by LLMs
- Keep the format consistent: `<user_environment>{json}</user_environment>`

## Dependencies of Note

- `reedline`: REPL functionality
- `syntect`: Syntax highlighting
- `serde/serde_yaml/serde_json`: Configuration and serialization
- `tokio`: Async runtime
- `reqwest`: HTTP client for API calls
- `sysinfo`: System information gathering (new)
- `which`: Command availability detection (new)
- `scraper`: HTML parsing for RAG

## Git Workflow

This is a fork with feature branches. Recent commits show:
- `eb1bcac`: feature .export
- `db5cd00`: feature: gpu, mem info
- `4187004`: feature: more sys info
- `60033ee`: feature: env info

## Notes

- The codebase uses Rust's strong type system extensively
- Async operations are handled with Tokio
- Configuration uses YAML for human-readability
- Errors are handled with `anyhow::Result`
- The code follows Rust 2021 edition conventions
- Environment detection should be fast (no network calls in critical path)
